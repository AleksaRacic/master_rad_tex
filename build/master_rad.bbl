\begin{thebibliography}{10}

\bibitem{rocha_discovering_2021}
K.~Rocha {\em et~al.}, ``Discovering the sentiment in finance's unstructured
  data,'' 2021.

\bibitem{paro_ai_strategic_2023}
{Paro AI}, ``The strategic benefits of {NLP} in finance,'' 2023.

\bibitem{yang_evaluating_2025}
Z.~Yang {\em et~al.}, ``Evaluating {LLMs} in financial {NLP}: A comparative
  study on financial report analysis,'' 2025.

\bibitem{noauthor_artificial_20233}
``Artificial neuron,'' Aug. 2023.
\newblock Page Version ID: 1170144985.

\bibitem{ioannou_structural_2017}
Y.~Ioannou, {\em Structural {Priors} in {Deep} {Neural} {Networks}}.
\newblock PhD thesis, Sept. 2017.

\bibitem{anwar_learned_2017}
I.~Anwar and N.~Ul~Islam, ``Learned {Features} are {Better} for {Ethnicity}
  {Classification},'' {\em Cybernetics and Information Technologies}, vol.~17,
  Sept. 2017.

\bibitem{noauthor_artificial_2023}
``Artificial neural network,'' Sept. 2023.
\newblock Page Version ID: 1175471829.

\bibitem{gage_new_1994}
P.~Gage, ``A new algorithm for data compression,'' {\em C Users Journal},
  vol.~12, no.~2, pp.~24--35, 1994.

\bibitem{sennrich_neural_2016}
R.~Sennrich, B.~Haddow, and A.~Birch, ``Neural machine translation of rare
  words with subword units,'' in {\em Proceedings of the 54th Annual Meeting of
  the Association for Computational Linguistics (Volume 1: Long Papers)},
  pp.~1715--1725, Association for Computational Linguistics, 2016.

\bibitem{vaswani_attention_2017}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in {\em Advances
  in Neural Information Processing Systems 30}, pp.~5998--6008, Curran
  Associates, Inc., 2017.

\bibitem{bahdanau_neural_2015}
D.~Bahdanau, K.~Cho, and Y.~Bengio, ``Neural machine translation by jointly
  learning to align and translate,'' {\em arXiv preprint arXiv:1409.0473},
  2015.

\bibitem{brown_language_2020}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, S.~Agarwal, A.~Herbert-Voss,
  G.~Krueger, T.~Henighan, R.~Child, A.~Ramesh, D.~M. Ziegler, J.~Wu,
  C.~Winter, C.~Hesse, M.~Chen, E.~Sigler, M.~Litwin, S.~Gray, B.~Chess,
  J.~Clark, C.~Berner, S.~McCandlish, A.~Radford, I.~Sutskever, and D.~Amodei,
  ``Language models are few-shot learners,'' in {\em Advances in Neural
  Information Processing Systems 33}, pp.~1877--1901, Curran Associates, Inc.,
  2020.

\bibitem{lu_large_2024}
Z.~Lu, ``Large language models: Development in model scale and challenges,''
  {\em Applied and Computational Engineering}, vol.~114, pp.~154--161, 2024.

\bibitem{martineau_whats_2024}
K.~Martineau, ``What's an {LLM} context window and why is it getting larger?,''
  2024.

\bibitem{liu_lost_2023}
N.~F. Liu, K.~Lin, J.~Hewitt, A.~Paranjape, M.~Bevilacqua, F.~Petroni, and
  P.~Liang, ``Lost in the middle: How language models use long contexts,''
  2023.

\bibitem{sahoo_systematic_2025}
P.~Sahoo, A.~K. Singh, S.~Saha, V.~Jain, S.~Mondal, and A.~Chadha, ``A
  systematic survey of prompt engineering in large language models: Techniques
  and applications,'' 2025.

\bibitem{lewis_retrieval_2020}
P.~Lewis, E.~Perez, A.~Piktus, F.~Petroni, V.~Karpukhin, N.~Goyal,
  H.~K{\"{u}}ttler, M.~Lewis, W.-t. Yih, T.~Rockt{\"{a}}schel, S.~Riedel, and
  D.~Kiela, ``Retrieval-augmented generation for knowledge-intensive {NLP}
  tasks,'' in {\em Advances in Neural Information Processing Systems 33},
  pp.~9459--9474, Curran Associates, Inc., 2020.

\bibitem{yang_dual_2025}
Q.~Yang {\em et~al.}, ``Dual retrieving and ranking medical {LLM} with
  retrieval augmented generation,'' {\em Scientific Reports}, vol.~15,
  p.~18062, 2025.

\bibitem{kim_large_2024}
M.~Kim, ``Large context windows versus {RAG},'' 2024.

\bibitem{islam_financebench_2023}
P.~Islam, A.~Kannappan, D.~Kiela, R.~Qian, N.~Scherrer, and B.~Vidgen,
  ``{FinanceBench}: {A} {New} {Benchmark} for {Financial} {Question}
  {Answering},'' 2023.
\newblock arXiv:2311.11944 [cs].

\bibitem{openai_function_calling_2023}
{OpenAI}, ``Function calling and other api updates.'' OpenAI News, 2023.

\bibitem{cheung_llama2_vs_gpt4_2023}
D.~Cheung, ``Meta llama 2 vs. openai gpt-4: A comparative analysis.'' Medium,
  2023.

\bibitem{anthropic_best_practices_2025}
{Anthropic}, ``Using anthropic: Best practices, parameters, and large context
  windows.'' PromptHub Blog, 2025.

\bibitem{kramer_deepseek_2025}
N.~Kramer, ``Deepseek: Everything you need to know about this new llm in one
  place.'' daily.dev, 2025.

\bibitem{ibm_what_is_langchain_2023}
{IBM}, ``What is langchain?.'' IBM Think Blog, 2023.

\bibitem{patriwala_langchain_2025}
A.~Patriwala, ``Langchain: A comprehensive framework for building llm
  applications.'' Medium, 2025.

\bibitem{langchain_docs_2024}
{LangChain}, ``Langchain documentation.'' Online Documentation, 2024.

\bibitem{yao_react_2022}
S.~Yao, D.~Zhao, T.~Yu, N.~Du, I.~Shafran, K.~Narasimhan, and Y.~Cao, ``React:
  Synergizing reasoning and acting in language models,'' in {\em Proceedings of
  the International Conference on Learning Representations (ICLR)}, 2023.

\bibitem{pypi_edgar_2024}
{PyPI}, ``edgar library, v5.6.3.'' Python Package Index (PyPI), 2024.

\bibitem{sec_parser_docs_2023}
{sec-parser documentation}, ``sec-parser: Semantic parsing for sec filings,''
  2023.

\bibitem{sec_api_tutorial_2023}
{sec-api.io}, ``Extract textual data from edgar 10-k filings using python.''
  Tutorial, 2023.

\bibitem{evidently_ai_llm_judge_2025}
{Evidently AI}, ``Llm-as-a-judge: a complete guide to using llms for
  evaluations.'' Evidently AI Blog, 2025.

\bibitem{zheng_judging_llm_2023}
L.~Zheng, W.-L. Chiang, Y.~Sheng, S.~Zhuang, Z.~Wu, Y.~Zhuang, Z.~Lin, Z.~Li,
  D.~Li, E.~P. Xing, H.~Zhang, J.~E. Gonzalez, and I.~Stoica, ``Judging
  llm-as-a-judge with mt-bench and chatbot arena,'' {\em arXiv preprint
  arXiv:2306.05685}, 2023.

\bibitem{clearwater_analytics_2023}
{Clearwater Analytics}, ``A cutting-edge framework for evaluating llm output.''
  Clearwater Analytics Blog, 2023.

\bibitem{verga_replacing_judges_2024}
P.~Verga, N.~Elaraby, S.~Joshi, S.~Min, D.~Chen, and X.~Ling, ``Replacing
  judges with juries: Evaluating llm generations with a panel of diverse
  models,'' {\em arXiv preprint arXiv:2404.18796}, 2024.

\end{thebibliography}
