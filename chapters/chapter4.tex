\chapter{Преглед алата и радног оквира}
\label{sec:llm_agent}

\section{Основни модел}

У оквиру развоја агента заснованог на великим језичким моделима, први корак је одабир одговарајућег основног модела. Разматрају се водећи LLM модели у рангу GPT-4, укључујући OpenAI GPT-4, Anthropic Claude 2, DeepSeek и Meta LLaMA~2. Ови модели се упоређују по перформансама, величини, величини контекста, доступности и цени, као и могућностима за позивање алата (енг. tool calling). Нарочито је битно размотрити да ли модел подржава интеграцију са спољним алатима, јер наш агент треба да користи екстерне алате ради проширивања функционалности.

Да бисмо систематично сагледали карактеристике, табела испод пореди ове моделе:

\begin{table}[h]
\centering
\footnotesize
\begin{threeparttable}
\begin{tabular}{|m{3.5cm}|m{3.0cm}|m{3.8cm}|m{4.2cm}|}
\hline
    \textbf{Модел} & \textbf{Контекст} & \textbf{Доступност/API} & \textbf{Подршка за алате} \\
\hline
OpenAI GPT-4 & 8k--32k (до 128k у новијим верзијама) & Комерцијални API & Да\tnote{a} \\
\hline
Anthropic Claude 2 & 100k токена & Комерцијални API & Делимично -- преко инструкција (без званичног API-ја за функције) \\
\hline
DeepSeek LLM & до 128k токена & Отворен код & Не -- кроз спољну оркестрацију \\
\hline
Meta LLaMA~2 (70B) & \(\sim\)4k токена & Отворен код & Не -- кроз спољну оркестрацију \\
\hline
\end{tabular}
\begin{tablenotes}
\item[a] OpenAI подржава опис интерфејса функција и поврат структурираних JSON позива \cite{openai_function_calling_2023}.
\end{tablenotes}
\end{threeparttable}
\caption{Поређење напредних LLM модела у рангу GPT-4 по величини, контексту, цени и подршци за алате.}
\label{tab:llm_comparison}
\end{table}

Из табеле је јасно да GPT-4 остаје златни стандард по квалитету генерације и разумевања. Иако је власнички модел затвореног кода, GPT-4 демонстрира врхунске перформансе на бројним задацима: на пример, постиже успех од \(86.4\%\) на мултидисциплинарном тесту MMLU у поређењу са \(\sim68.9\%\) код LLaMA~2 \cite{cheung_llama2_vs_gpt4_2023}. Такође надмашује отворене моделе у кодирању (HumanEval тест \(\sim67\%\) насупрот \(\sim30\%\) за LLaMA~2) и математичком резоновању. Anthropic Claude~2 је по квалитету често упоредив са GPT-4, али му је главна предност изузетно велики контекст од \(100\,000\) токена, што омогућава унос стотина страна текста у једном упиту; притом је цена по 1000 токена око \$0.011 за улаз и \$0.033 за излаз, што је знатно повољније од GPT-4 \cite{anthropic_best_practices_2025}. Насупрот томе, отворени модели DeepSeek и LLaMA~2 доносе предност у погледу доступности и трошкова -- могу се самостално хостовати без плаћања по упиту. DeepSeek је нарочито занимљив због своје Mixture-of-Experts архитектуре: иако има укупно 671B параметара, за било који задатак активно је само \(\sim37\)B параметара, што смањује рачунарни трошак, а при том постиже висок учинак (нпр. \(\sim73.8\%\) на HumanEval) и подржава дугачак контекст до 128k токена \cite{kramer_deepseek_2025}. Међутим, упркос напретку ових модела, OpenAI GPT-4 и даље има предност у општој поузданости и способности сложеног резоновања.
\newline

Посебно значајан фактор за изградњу агента је способност модела да позива спољне алате. У том погледу, OpenAI GPT-4 нуди готову подршку за позивање функција. Механизам где се моделу опише интерфејс функције, након чега модел по потреби враћа структуриран JSON позив те функције уместо обичног текста \cite{openai_function_calling_2023}. Ова функционалност омогућава да GPT-4 поуздано иницира извршавање екстерних алата или API позива ради прибављања додатних информација или извршавања задатака. Насупрот томе, други модели у табели тренутно немају уграђену подршку за директно позивање функција. Claude~2 се може инструисати да користи алате путем промпта, али не постоји званичан API за функције те се свака интеграција мора ручно оркестрирати. Слично, LLaMA~2 и DeepSeek, као отворени модели, могу користити алате једино уз помоћ спољних библиотека и логике.
\newline

Имајући у виду све наведено, најсавременији квалитет генерисања текста, широку подршку у академским и индустријским тестовима, као и нативну могућност позивања алата -- за ову истраживачку примену одабрали смо OpenAI GPT-4 као основни LLM модел. Иако захтева финансијска улагања, GPT-4 ће обезбедити највиши ниво разумевања сложених извештаја и поуздано руковање алатима неопходним за анализу 10-K финансијских докумената. Очекивано је да ће овај модел, уз правилну оркестрацију, најбоље испунити захтеве агента у погледу тачности и функционалности.


\section{Преглед алата за окетрацију и обраду упита}

За изградњу комплексног система заснованог на великом језичком моделу, потребно је користити одговарајуће библиотеке за оркестрацију у раду са великим језичким моделима и инжењеринг упита. Ове библиотеке пружају структуру и алате да се LLM интегрише у апликацију, управља током разговора, памти контекст и позива спољне изворе података или алате. На располагању је више популарних open-source решења, као и комерцијалних оквира, за ову намену. Нека од значајних су:
\newline

\begin{itemize}
    \item \textbf{LangChain} -- отворени оквир за оркестрацију LLM апликација написан у Python и JavaScript. Пружа модуларне компоненте за креирање ланаца операција и агената, са подршком за меморију, шаблоне упита и интеграцију алата \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.
    \item \textbf{LlamaIndex} (раније GPT Index) -- библиотека фокусирана на повезивање LLM-ова са документима путем индекса (нпр. за претрагу информација у великом корпусу докумената) \cite{patriwala_langchain_2025}.
    \item \textbf{Haystack} -- оквир за претраживање који подржава интеграцију LLM-ова у проточној обради за преузимање информација и одговарање на упите \cite{patriwala_langchain_2025}.
    \item \textbf{Semantic Kernel} (Microsoft) -- SDK за креирање комплексних апликација са LLM-овима, наглашавајући могућност проширења (енг. plugins) и композицију функција у оквиру .NET/Python окружења.
\end{itemize}

Наведенa решења омогућавају оркестрацију позива LLM модела и других услуга у више корака. На пример, уместо да једноставно пошаљемо упит моделу, помоћу ових библиотека можемо раздвојити сложени задатак на секвенцу корака: претрага релевантних докумената, сумирање делова текста, затим генерисање финалног одговора. Оркестрациони оквир управља током извршавања ових корака и разменом података са LLM-ом. Осим тога, библиотеке за LLM оркестрацију апстрахују детаље конкретних API-ја различитих провајдера модела, што омогућава лако експериментисање и замену модела у позадини \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}. На пример, једноставно је могуће конфигурисати систем да користи GPT-4 за један задатак, а Claude~2 или LLaMA за други, без значајних промена у логици апликације.
\newline

После разматрања више опција \textbf{LangChain} се издваја као најпогоднија библиотека за пројекат. Разлози за одабир LangChain-а произилазе из његових предности:
\newline

\begin{itemize}
    \item \textbf{Модуларна архитектура ланаца и агената:} LangChain омогућава дефинисање ланаца (енг. \textit{chains}) -- секвенци операција које укључују LLM позиве и друге акције -- као и агената који користе LLM за доношење одлука о наредним корацима \cite{patriwala_langchain_2025}.
    \item \textbf{Интеграција вишеструких LLM модела:} Уграђана подршка за бројне провајдере и моделе, са обједињеним интерфејсом ка OpenAI, Anthropic, HuggingFace и др. \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.
    \item \textbf{Памћење и управљање контекстом:} Механизми меморије за конверзацијске системе (краткорочно и дугорочно) који омогућавају природније дијалоге \cite{patriwala_langchain_2025}.
    \item \textbf{Шаблонирање и инжењеринг упита:} Шаблони промптова и динамичко попуњавање контекстом за конзистентне улазе моделу \cite{patriwala_langchain_2025}.
    \item \textbf{Повезивање са спољним алатима и изворима:} Једноставна интеграција претраживача, база знања, калкулатора, веб API-ја, web scraping-а и база података \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.
    \item \textbf{Заједница и документација:} Богата документација и активна заједница, са многим примерима и туторијалима \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.
\end{itemize}

На основу наведених карактеристика, LangChain се истиче као свеобухватан и флексибилан оквир погодан за наш задатак. Он нам омогућава да дефинишемо агента који корак-по-корак обрађује упит корисника: од иницијалног разумевања питања, преко претраживања потребних информација у 10-K извештајима, до генерисања коначног одговора који комбинује пронађене податке и закључке модела. Алтернативна решења (поменута горе) такође нуде сличне могућности, али LangChain представља стандард у индустрији због богатства функција и доказа успешних примена.

\subsection{Преглед LangChain библиотеке}

LangChain је свеобухватан оквир који омогућава развој сложених апликација заснованих на великим језичким моделима \cite{langchain_docs_2024}. У наставку се детаљније разматрају кључне компоненте ове библиотеке које су релевантне за имплементацију финансијског агента.

\subsubsection{Креирање упита}

LangChain користи концепт ланаца (енг. Chain) за извршавање упита над LLM моделима. При томе се најчешће прави упитни шаблон који садржи места за унос променљивих вредности, а затим се тај шаблон повезује са моделом у оквиру ланца. Упитни шаблон (енг. Prompt Template) је предложак текста који комбинује фиксна упутства са променљивим деловима које попуњава кориснички унос \cite{langchain_docs_2024}. На пример, можемо дефинисати шаблон који преводи задати текст на француски, где је само део текста променљив. Када направимо такав шаблон, креирамо објекат ланца који повезује изабрани LLM модел са датим шаблоном упита. На тај начин, сваки пут када позовемо ланац, довољно је да проследимо конкретне вредности за променљиве у шаблону, а LangChain ће аутоматски саставити пуни упит и проследити га моделу \cite{langchain_docs_2024}.

Кориснички унос се дакле убацује у ипитни шаблон и формира се коначан текст упита, који LLM обрађује и враћа резултат. Следи пример израде једноставног ланца са prompt шаблоном и његовог покретања:

\begin{lstlisting}[language=Python, caption={Пример креирања ланца са prompt шаблоном}, label={lst:langchain_prompt_template}]
from langchain import PromptTemplate, LLMChain
from langchain.chat_models import ChatOpenAI

# 1. Дефинишемо prompt шаблон са променљивом {text}
prompt = PromptTemplate(
    template="Преведи на француски следећи текст: {text}",
    input_variables=["text"]
)

# 2. Иницијализујемо LLM модел (нпр. OpenAI ChatGPT модел)
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)

# 3. Креирамо ланац који повезује модел и prompt шаблон
chain = LLMChain(llm=llm, prompt=prompt)

# 4. Покрећемо ланац прослеђивањем конкретне вредности за {text}
result = chain.run({"text": "Hello, how are you?"})
print(result)
\end{lstlisting}

У примеру кода \ref{lst:langchain_prompt_template}, упитни шаблон садржи текст са уметнутом променљивом \textit{\{text\}} и дефинише се листа његових променљивих. Затим се иницијализује LLM и креира се LLMChain који инкапсулира логику: узима задати prompt шаблон, попуњава га уносом, шаље моделу упит и враћа одговор. Позив \textit{chain.run} аутоматски убацује дат текст у место \textit{\{text\}} и прослеђује комплетан упит моделу, након чега добијамо преведени текст као резултат. Оваква структура омогућава да једном дефинишемо шаблон и модел, а да затим више пута извршавамо упите само прослеђивањем различитих улазних вредности.

\subsubsection{Регистрација алата}

У изградњи агената, алати (енг. Tools) представљају функције или оперативне методе које агент може динамички позивати током свог резоновања. Сваки алат се састоји од саме функције коју позива LLM, али и од метаподатака: пре свега име и опис. Име алата мора бити јединствено у листи алата и служи да се на њега реферише у упутствима агенту, док опис објашњава шта алат ради и даје контекст LLM-у за које задатке је тај алат користан \cite{langchain_docs_2024}. Добро описани алати омогућавају моделу да из описа закључи када и како да их употреби. Поред тога, се могу дефинисати шеме аргумената за сложеније алате.

LangChain пружа више начина за регистровање алата. Најједноставнији је да имамо обичну Python функцију и да од ње направимо алат. Можемо користити класу Tool из LangChain библиотеке, којој прослеђујемо:
\begin{itemize}
    \item \textbf{name:} назив алата (стринг),
    \item \textbf{func:} референцу на функцију коју извршава,
    \item \textbf{description:} опис намене алата.
\end{itemize}

Размотримо пример једноставног алата -- функције која враћа тренутни датум. Прво ћемо дефинисати Python функцију, а затим је регистровати као алат са именом и описом:

\begin{lstlisting}[language=Python, caption={Регистрација простог алата за тренутни датум}, label={lst:simple_tool_registration}]
from datetime import datetime
from langchain_core.tools import Tool

# Define function that returns current date in YYYY-MM-DD format
def get_current_date() -> str:
    """Returns current date as string in YYYY-MM-DD format."""
    return datetime.now().strftime("%Y-%m-%d")

# Create Tool object for tool registration
current_date_tool = Tool(
    name="get_current_date",
    func=get_current_date,
    description="Useful when agent needs today's date in YYYY-MM-DD format"
)
\end{lstlisting}

Горњи пример кода \ref{lst:simple_tool_registration} илуструје креирање прилагођеног алата. Функција \textit{get\_current\_date} има једноставан документован опис који објашњава шта ради. Затим конструишемо Tool објекат коме дајемо јединствено име \texttt{get\_current\_date}, прослеђујемо саму Python функцију, и наведемо опис алата. Опис ће LangChain укључити у промпт агента тако да LLM зна да тај алат даје тренутни датум, те ће га позвати када кориснички задатак то захтева. После овакве регистрације, тај алат додајемо у листу алата које агент може користити (нпр. tools = [current\_date\_tool]). Уколико бисмо имали више алата, све их укључимо у ту листу коју касније предајемо агенту.
\newline

\subsubsection{Коришћење меморије}

Да би разговор са агентом био кохерентан и контекстуалан, неопходно је да агент има неку врсту меморије. Меморија омогућава да агент зна шта је већ речено у разговору, тако да може да користи тај контекст при генерисању следећих одговора. Без меморије, сваки упит би се третирао изоловано, што би довело до фрагментираних, неповезаних разговора \cite{langchain_docs_2024}. LangChain зато обезбеђује класе за меморију које се могу укључити у ланце или агенте.

Постоји више врста меморије у LangChain-у, а две важне су:
\begin{itemize}
    \item \textbf{ConversationBufferMemory} -- меморија која чува комплетну историју разговора као низ порука (сваког питања корисника и одговора модела). Она представља најједноставнији облик: свака нова интеракција се додаје на крај меморијског буфера. Овај приступ осигурава да модел увек има комплетан контекст свих претходних размена, али може довести до великог броја токена ако је разговор дугачак.
    \item \textbf{ConversationSummaryMemory} -- меморија која чува сажетак разговора уместо пуне историје. Користи LLM да након одређеног броја интеракција или када историја постане предуга, сажме досадашњи разговор у краћи резиме, који се затим користи као контекст уместо оригиналних порука. На тај начин се штеди на дужини контекста (мање потрошених токена), омогућавајући дуже разговоре \cite{langchain_docs_2024}. Предност овог приступа је што агент може водити значајно дужи дијалог без губитка целокупног контекста, по цену ослањања на модел да направи добар сажетак.
\end{itemize}

Меморија је битна јер побољшава конзистентност агента: ако корисник постави пратеће питање, агент може да се позове на раније податке. На пример, ако корисник најпре пита „Какво је време у Токију данас?'', а затим „А шта је са сутрашњим временом?'', агент уз меморију разуме да се друго питање односи на временску прогнозу у Токију без да му се то експлицитно понови \cite{langchain_docs_2024}. Без меморије, агент би сваки пут видео само појединачно питање и не би повезао да се ``сутра'' односи на исти град.

У пракси, додавање меморије агенту у LangChain-у је једноставно -- при инициализацији ланца или агента проследимо објекат меморије као параметар. Приликом сваког позива, LangChain ће аутоматски ажурирати меморију новим корисничким уносом и одговором модела. Укратко, интеграција меморије се изводи овако:

\begin{lstlisting}[language=Python, caption={Креирање агента са меморијом}, label={lst:agent_with_memory}]
from langchain.memory import ConversationBufferMemory
from langchain.agents import initialize_agent, AgentType

# 1. Креирамо објекат меморије (овде бафер који чува целу историју)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# 2. Иницијализујемо LLM модел и листу алата (нпр. из претходне секције)
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
tools = [current_date_tool]  # листа алата, претходно дефинисана

# 3. Иницијализујемо агента са меморијом
agent_chain = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# 4. Сада агенту можемо поставити упит, а меморија ће се аутоматски ажурирати
response = agent_chain.run("Koji je danas datum?")
print(response)
\end{lstlisting}

У горњем примеру \ref{lst:agent_with_memory}, користимо ConversationBufferMemory за чување историјата разговора (параметар memory\_key=``chat\_history'' одређује назив променљиве у шаблону промпта где ће се меморија убацити, а return\_messages=True да меморија враћа листу порука уместо спојеног низа). Затим правимо агента помоћу функције initialize\_agent, прослеђујући листу алата, LLM, тип агента и објекат меморије. Када позовемо agent\_chain.run, агент ће добити приступ меморији и сваки његов одговор биће заснован на комплетном контексту разговора. После позива, memory објекат ће садржати и управо постављено питање и одговор, што омогућава агенту да на следеће питање одговори у контексту целе претходне конверзације.

\subsubsection{Реактивно покретање агента}

Реактивно покретање агента описан у секцији \ref{sec:reactive_approach} је приступ за изградњу интелигентних агената који могу динамички да користе алате током резоновања. Уместо да агент само генерише одговор на основу унапред дефинисаног упита, ReAct агенти могу да размишљају корак по корак, доносе одлуке о томе које алате да позову и како да интерпретирају резултате тих позива у контексту задатка \cite{yao_react_2022}. Овај приступ омогућава агенту да буде много флексибилнији и способнији за сложене задатке који захтевају више корака резоновања и интеракције са спољним изворима података.

У LangChain-у, да би агент радио у ReAct режиму, потребно је да буде конфигурисан са списком алата које сме да користи, одговарајућим LLM моделом, и (опционо) меморијом за вођење дијалога. Такође му је потребан упит који имплементира ReAct логику. То обично специјално дизајниран шаблон који агенту даје инструкције да користи формат Мисао/Акција/Опажање. LangChain већ садржи уграђене упитне шаблоне за ReAct агенте, тако да их није нужно ручно писати. При креирању агента, може се искористити константу типа агента AgentType.ZERO\_SHOT\_REACT\_DESCRIPTION, што означава управо ReAct агента који из описа алата бира који му је потребан (zero-shot приступ без претходних примера) \cite{langchain_docs_2024}. У примерима, већ смо користили функцију initialize\_agent са тим типом да направимо агента. Алтернативно, LangChain нуди и функцију create\_react\_agent за експлицитно прављење ReAct агента, као и класу AgentExecutor којом се финални агент покреће \cite{langchain_docs_2024}. 

У пракси, initialize\_agent(..., agent=AgentType.ZERO\_SHOT\_REACT\_DESCRIPTION, ...) враћа управо AgentExecutor спреман за коришћење.
\newline

Пример покретања агента у ReAct режиму је приказан у примеру кода \ref{lst:run_react_agent}. Под претпоставком да је агент са именом agent\_chain који има један алат (get\_current\_date) и меморију већ иницијализован. Поставља се упит који захтева комбиновано резоновање и коришћење алата, на пример: ``Који је данас датум и колико дана има до краја месеца?''. ReAct агент треба прво да схвати да му је потребан данашњи датум, да га дохвати, а онда да израчуна преостале дане у месецу. Покренимо агента:

\begin{lstlisting}[language=Python, caption={Покретање ReAct агента}, label={lst:run_react_agent}]
query = "Који је данас датум и колико дана има до краја месеца?"
response = agent_chain.run(query)
print(response)
\end{lstlisting}

Приликом оваквог позива, агент ће интерно генерисати низ ``мисли'' и ``акција''. Могући ток би изгледао овако:
\begin{enumerate}
    \item Мисао: ``Питање тражи данашњи датум и број дана до краја месеца. Прво треба да сазнам данашњи датум.''
    \item Акција: Позива алат get\_current\_date.
    \item Опажање: Алат враћа, рецимо, ``2025-09-19''.
    \item Мисао: ``Данас је 19. септембар 2025. Треба израчунати колико дана има до 30. септембра 2025.''.
    \item Акција: (Није неопходна нова спољна акција, модел може сам да рачуна)
    \item Опажање: (Није примењиво, рачун је унутрашњи)
    \item Мисао: ``Остало је 11 дана до краја септембра.''
    \item Коначан одговор: ``Данас је 19. септембар 2025. године, и преостало је 11 дана до краја месеца.''
\end{enumerate}

Наравно, сам корисник добија само коначни одговор, док су кораци размишљања и акције извршене у позадини. Реактивно понашање овде се огледа у томе да агент није унапред знао које ће алате употребити или какву ће стратегију применити, већ је динамички одлучивао у ходу на основу самог питања и резултата међукорака. LangChain-ов ReAct агент уз помоћ AgentExecutor-а управља овим циклусом, што програмеру омогућава да једноставно проследи упит агенту као једну функцију, док се сложена логика одвија аутоматски. Резултат је снажан систем који може да обавља комплексне задатке комбинујући више корака резоновања и коришћења алата, дајући прецизне и контекстуалне одговоре \cite{langchain_docs_2024}.



\section{Python EDGAR библиотеке за обраду 10-K извештаја}

За потребе издвајања података, потребно је аутоматски приступати 10-K извештајима и из њих издвајати одређене информације које ће LLM анализирати.

Неколико истакнутих Python алата за рад са EDGAR подацима су:
\newline

\begin{itemize}
    \item \textbf{edgar} библиотека: Једноставна Python библиотека која пружа интерфејс за приступ EDGAR архиви; омогућава претрагу по називу или CIK, преузимање најновијег 10-K и екстракцију текста \cite{pypi_edgar_2024}.
    \item \textbf{EDGAR API клијенти:} Модерни клијенти за званични SEC API омогућавају претрагу поднесака и директно преузимање у JSON/XML облику.
    \item \textbf{Парсери SEC докумената:} \textit{sec-parser} разлаже HTML 10-K на семантичке секције (наслови, пасуси, табеле), што поуздано омогућава извлачење релевантних делова попут ``Item 1A. Risk Factors'' \cite{sec_parser_docs_2023}.
    \item \textbf{SEC Extractor API (sec-api):} Комерцијални API и Python пакет за једноставно извлачење конкретних одељака (нпр. ``Item 7'') и конверзију табела у структуре погодне за анализу \cite{sec_api_tutorial_2023}.
\end{itemize}

У примени нашег агента, планирамо да користимо комбинацију наведених техника: аутоматизовано преузимање 10-K извештаја (edgar/SEC API), почетно парсирање (\textit{sec-parser}/sec-api) и усмерено прослеђивање релевантних сегмената LLM-у. Овај корак претходне обраде смањује количину текста коју LLM анализира (трошак/прозор контекста) и повећава тачност података које модел разматра. Уз LangChain-ове документ лоудере и векторске базе, 10-K делови могу се индексирати ембединзима и претраживати семантички у RAG парадигми \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.

На основу доступне литературе и алата, можемо илустровати могућности овакве обраде на конкретном примеру: узимање последњег 10-K извештаја компаније IBM и екстракција два различита дела. Прво, користећи \textit{edgar} библиотеку, преузимамо HTML садржај извештаја и потом га прослеђујемо \textit{sec-parser} алату који га дели на семантичке секције. Потом:
\begin{itemize}
    \item Ако желимо квалитативне информације, попут описа пословања и ризика, можемо из парсираног стабла издвојити чланке означене као ``Item 1. Business'' или ``Item 1A. Risk Factors'' и добити чист текст тих секција. Ове секције често садрже више пасуса текста и могу бити обрађене LLM-ом ради сумирања или Q\&A (нпр. „Како компанија описује утицај конкуренције на своје пословање у последњем 10-K?").
    \item Ако су нам потребне квантитативне информације, попут финансијских показатеља, можемо фокусирано извући табеларне делове 10-K. Коришћењем \textit{sec-api} или мануелно уз \textit{BeautifulSoup}, могуће је наћи табеле (нпр. биланс успеха, биланс стања) и конвертовати их у структуру погодну за анализу (рецимо DataFrame у Pandas-у). Тај бројчани контекст можемо проследити LLM моделу уз упутство да га протумачи (нпр. „На основу приложене табеле прихода и расхода из последње три године, објасни тренд прихода компаније.").
\end{itemize}

Закључно, Python EDGAR алати значајно проширују могућности LLM агента, омогућавајући му да буде специјализован за рад са извештајима. Комбинујући те податке са моћним разумевањем језика модела GPT-4, систем може да даје квалитетне одговоре -- како описне (сумирање наративних делова), тако и аналитичке (поређење метрика) -- на питања у вези са пословањем компанија. Овај интегрисани приступ спаја снагу LLM-а са прецизношћу доменских алата, што је кључно за научно-истраживачки рад који укључује обраду великих текстуалних финансијских података.