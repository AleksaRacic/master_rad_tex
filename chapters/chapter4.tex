\chapter{Преглед алата}
\label{sec:llm_agent}

\section{Основни модел}

У оквиру развоја агента заснованог на великим језичким моделима (енг. Large Language Model -- LLM), први корак је одабир одговарајућег основног модела. Разматрају се водећи LLM модели у рангу GPT-4, укључујући OpenAI GPT-4, Anthropic Claude~2, DeepSeek и Meta LLaMA~2. Ови модели се упоређују по перформансама, величини (броју параметара), дужини контекстуалног прозора, доступности/API и цени, као и могућностима за позивање алата (енг. tool calling). Нарочито је битно размотрити да ли модел подржава интеграцију са спољним алатима, јер наш агент треба да користи екстерне алате ради проширивања функционалности.

Да бисмо систематично сагледали карактеристике, табела испод пореди ове моделе:

\begin{table}[h]
\centering
\footnotesize
\begin{threeparttable}
\begin{tabular}{|p{2.9cm}|p{2.6cm}|p{2.6cm}|p{3.1cm}|p{3.1cm}|p{3.0cm}|}
\hline
    extbf{Модел} & \textbf{Параметри} & \textbf{Контекст} & \textbf{Доступност/API} & \textbf{Цене (по 1k токена)} & \textbf{Подршка за алате} \\
\hline
OpenAI GPT-4 & \textasciitilde{}1.7T (процена) & 8k--32k (до 128k у новијим верзијама) & Комерцијални API (OpenAI) & \$\sim{}0.03 улаз, \$\sim{}0.06 излаз & Да -- нативно позивање функција (function calling)\tnote{a} \\
\hline
Anthropic Claude~2 & (није јавно објављено; \(\approx\)100B+) & 100k токена & Комерцијални API (Anthropic) & \$\sim{}0.011 улаз, \$\sim{}0.033 излаз & Делимично -- преко инструкција (без званичног API-ја за функције) \\
\hline
DeepSeek LLM & 671B (MoE, \(\sim\)37B активно) & до 128k токена & Отворен код (самохостовање) & Н/П (трошак хардвера; \(\sim\)95\% мање по токену у односу на GPT-4) & Не -- кроз спољну оркестрацију \\
\hline
Meta LLaMA~2 (70B) & 70B & \(\sim\)4k токена (стандардно) & Отворен код (локално, HuggingFace) & Бесплатно (рачунарски ресурси) & Не -- кроз спољну оркестрацију \\
\hline
\end{tabular}
\begin{tablenotes}
\item[a] OpenAI подржава опис интерфејса функција и поврат структурираних JSON позива \cite{openai_function_calling_2023}.
\end{tablenotes}
\end{threeparttable}
\caption{Поређење напредних LLM модела у рангу GPT-4 по величини, контексту, цени и подршци за алате.}
\label{tab:llm_comparison}
\end{table}

Из табеле је јасно да GPT-4 остаје златни стандард по квалитету генерације и разумевања. Иако је власнички модел затвореног кода, GPT-4 демонстрира врхунске перформансе на бројним задацима: на пример, постиже успех од \(86.4\%\) на мултидисциплинарном тесту MMLU у поређењу са \(\sim68.9\%\) код LLaMA~2 \cite{cheung_llama2_vs_gpt4_2023}. Такође надмашује отворене моделе у кодирању (HumanEval тест \(\sim67\%\) насупрот \(\sim30\%\) за LLaMA~2) и математичком резоновању. Anthropic Claude~2 је по квалитету често упоредив са GPT-4, али му је главна предност изузетно велики контекст од \(100\,000\) токена, што омогућава унос стотина страна текста у једном упиту; притом је цена по 1000 токена око \$0.011 за улаз и \$0.033 за излаз, што је знатно повољније од GPT-4 \cite{anthropic_best_practices_2025}. Насупрот томе, отворени модели DeepSeek и LLaMA~2 доносе предност у погледу доступности и трошкова -- могу се самостално хостовати без плаћања по упиту. DeepSeek је нарочито занимљив због своје Mixture-of-Experts архитектуре: иако има укупно 671B параметара, за било који задатак активно је само \(\sim37\)B параметара, што смањује рачунарни трошак; при том постиже висок учинак (нпр. \(\sim73.8\%\) на HumanEval) и подржава дугачак контекст до 128k токена \cite{kramer_deepseek_2025}. Међутим, упркос напретку ових модела, OpenAI GPT-4 и даље има предност у општој поузданости и способности сложеног резоновања.

Посебно значајан фактор за изградњу LLM агента је способност модела да позива спољне алате. У том погледу, OpenAI GPT-4 нуди нативну подршку за позивање функција -- механизам где се моделу опише интерфејс функције, након чега модел по потреби враћа структуриран JSON позив те функције уместо обичног текста \cite{openai_function_calling_2023}. Ова функционалност омогућава да GPT-4 поуздано иницира извршавање екстерних алата или API позива (слично концепту ChatGPT прикључака) ради прибављања додатних информација или извршавања задатака. Насупрот томе, други модели у табели тренутно немају уграђену подршку за директно позивање функција. Claude~2 се може инструисати да користи алате путем промпта, али не постоји званичан API за функције -- свака интеграција мора се ручно оркестрирати. Слично, LLaMA~2 и DeepSeek, као отворени модели, могу користити алате једино уз помоћ спољних библиотека и логике (нпр. преко оквира као што је LangChain).

Имајући у виду све наведено -- најсавременији квалитет генерисања текста, широку подршку у академским и индустријским тестовима, као и нативну могућност позивања алата -- за ову истраживачку примену одабрали смо OpenAI GPT-4 као основни LLM модел. Иако захтева финансијска улагања, GPT-4 ће обезбедити највиши ниво разумевања сложених извештаја и поуздано руковање алатима неопходним за анализу 10-K финансијских докумената. Очекивано је да ће овај модел, уз правилну оркестрацију, најбоље испунити захтеве агента у погледу тачности и функционалности.


\section{Преглед алата за окетрацију и обраду упита}

За изградњу комплексног система заснованог на LLM моделу, потребно је користити одговарајуће библиотеке за оркестрацију LLM процеса и инжењеринг упита (енг. \textit{prompt engineering}). Ове библиотеке пружају структуру и алате да се LLM интегрише у апликацију, управља током разговора, памти контекст и позива спољне изворе података или алате. На располагању је више популарних open-source решења, као и комерцијалних оквира, за ову намену. Нека од значајних су:
\begin{itemize}
    \item \textbf{LangChain} -- отворени оквир за оркестрацију LLM апликација (Python/JavaScript). Пружа модуларне компоненте за креирање ланаца операција и агената, са подршком за меморију, шаблоне упита и интеграцију алата \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.
    \item \textbf{LlamaIndex} (раније GPT Index) -- библиотека фокусирана на повезивање LLM-ова са документима путем индекса (нпр. за претрагу информација у великом корпусу докумената) \cite{patriwala_langchain_2025}.
    \item \textbf{Haystack} -- оквир за претраживање и Q\&A који подржава интеграцију LLM-ова у pipeline за преузимање информација и одговарање на упите \cite{patriwala_langchain_2025}.
    \item \textbf{Semantic Kernel} (Microsoft) -- SDK за креирање комплексних апликација са LLM-овима, наглашавајући плугове (енг. plugins) и композицију функција у оквиру .NET/Python окружења.
\end{itemize}

Наведенa решења омогућавају програмерима да оркетрирају позиве LLM модела и других услуга у више корака. На пример, уместо да једноставно пошаљемо упит моделу, помоћу ових библиотека можемо раздвојити сложени задатак на секвенцу корака: претрага релевантних докумената, сумирање делова текста, затим генерисање финалног одговора. Оркестрациони оквир управља током извршавања ових корака и разменом података са LLM-ом. Осим тога, библиотеке за LLM оркестрацију апстрахују детаље конкретних API-ја различитих провајдера модела, што омогућава лако експериментисање и замену модела у позадини \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}. На пример, једноставно је могуће конфигурисати систем да користи GPT-4 за један задатак, а Claude~2 или LLaMA за други, без значајних промена у логици апликације.

После разматрања више опција, издвајамо \textbf{LangChain} као најпогоднију библиотеку за наш пројекат. Разлози за одабир LangChain-а произилазе из његових снажних страна:
\begin{itemize}
    \item \textbf{Модуларна архитектура ланаца и агената:} LangChain омогућава дефинисање ланаца (енг. \textit{chains}) -- секвенци операција које укључују LLM позиве и друге акције -- као и агената који користе LLM за доношење одлука о наредним корацима \cite{patriwala_langchain_2025}.
    \item \textbf{Интеграција вишеструких LLM модела:} Уграђана подршка за бројне провајдере и моделе, са унифицираним интерфејсом ка OpenAI, Anthropic, HuggingFace и др. \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.
    \item \textbf{Памћење и управљање контекстом:} Механизми меморије за конверзацијске системе (краткорочно и дугорочно) који омогућавају природније дијалоге \cite{patriwala_langchain_2025}.
    \item \textbf{Шаблонирање и инжењеринг упита:} Шаблони промптова и динамичко попуњавање контекстом за конзистентне улазе моделу \cite{patriwala_langchain_2025}.
    \item \textbf{Повезивање са спољним алатима и изворима:} Једноставна интеграција претраживача, база знања, калкулатора, веб API-ја, web scraping-а и база података \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.
    \item \textbf{Заједница и документација:} Богата документација и активна заједница, са многим примерима и туторијалима \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.
\end{itemize}

На основу наведених карактеристика, LangChain се истиче као свеобухватан и флексибилан оквир погодан за наш задатак. Он нам омогућава да дефинишемо агента који корак-по-корак обрађује упит корисника: од иницијалног разумевања питања, преко претраживања потребних информација у 10-K извештајима, до генерисања коначног одговора који комбинује пронађене податке и закључке модела. Алтернативна решења (поменута горе) такође нуде сличне могућности, али LangChain представља стандард у индустрији због богатства функција и доказа успешних примена.

\subsection{Преглед LangChain библиотеке}

LangChain је свеобухватан оквир који омогућава развој сложених апликација заснованих на великим језичким моделима \cite{langchain_docs_2024}. У наставку ћемо детаљније размотрити кључне компоненте ове библиотеке које су релевантне за изградњу нашег финансијског агента.

\subsubsection{Креирање упита (Query) у LangChain-у}

LangChain користи концепт ланаца (енг. Chain) за извршавање упита над LLM моделима. При томе се најчешће прави prompt шаблон који садржи места за унос променљивих вредности, а затим се тај шаблон повезује са моделом у оквиру ланца. Prompt шаблон (енг. Prompt Template) је предложак текста који комбинује фиксна упутства са променљивим деловима које попуњава кориснички унос \cite{langchain_docs_2024}. На пример, можемо дефинисати шаблон који преводи задати текст на француски, где је само део текста променљив. Када направимо такав шаблон, креирамо објекат ланца (нпр. LLMChain) који повезује изабрани LLM модел са датим шаблоном упита. На тај начин, сваки пут када позовемо ланац, довољно је да проследимо конкретне вредности за променљиве у шаблону, а LangChain ће аутоматски саставити пуни упит и проследити га моделу \cite{langchain_docs_2024}.

Кориснички унос (нпр. питање) се дакле убацује у prompt шаблон и формира се коначан текст упита, који LLM обрађује и враћа резултат. Следи пример израде једноставног ланца са prompt шаблоном и његовог покретања:

\begin{lstlisting}[language=Python, caption={Пример креирања ланца са prompt шаблоном}]
from langchain import PromptTemplate, LLMChain
from langchain.chat_models import ChatOpenAI

# 1. Дефинишемо prompt шаблон са променљивом {text}
prompt = PromptTemplate(
    template="Преведи на француски следећи текст: {text}",
    input_variables=["text"]
)

# 2. Иницијализујемо LLM модел (нпр. OpenAI ChatGPT модел)
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

# 3. Креирамо ланац који повезује модел и prompt шаблон
chain = LLMChain(llm=llm, prompt=prompt)

# 4. Покрећемо ланац прослеђивањем конкретне вредности за {text}
result = chain.run({"text": "Hello, how are you?"})
print(result)
\end{lstlisting}

У горњем примеру, PromptTemplate садржи текст са уметнутом променљивом \{text\} и дефинише се листа његових променљивих. Затим се иницијализује LLM (у овом случају OpenAI chat модел) и креира се LLMChain који инкапсулира логику: узима задати prompt шаблон, попуњава га уносом, шаље моделу упит и враћа одговор. Позив chain.run(\{...\}) аутоматски убацује дат текст у место \{text\} и прослеђује комплетан упит моделу, након чега добијамо преведени текст као резултат. Оваква структура омогућава да једном дефинишемо шаблон и модел, а да затим више пута извршавамо упите само прослеђивањем различитих улазних вредности.

\subsubsection{Регистрација алата (Tools)}

У изградњи агената, алати (енг. Tools) представљају функције или оперативне методе које агент може динамички позивати током свог резоновања. Сваки алат се састоји од саме функције коју позива LLM, али и од метаподатака: пре свега име и опис. Име алата мора бити јединствено у листи алата и служи да се на њега реферише у упутствима агенту, док опис објашњава шта алат ради и даје контекст LLM-у за које задатке је тај алат користан \cite{langchain_docs_2024}. Добро описани алати омогућавају моделу да из описа закључи када и како да их употреби. Поред тога, по потреби се могу дефинисати шеме аргумената (нпр. помоћу Pydantic модела) за сложеније алате, али једноставни случајеви захтевају само функцију, назив и опис.

LangChain пружа више начина за регистровање алата. Најједноставнији је да имамо обичну Python функцију и да од ње направимо алат. Можемо користити класу Tool из LangChain библиотеке, којој прослеђујемо:
\begin{itemize}
    \item \textbf{name:} назив алата (стринг),
    \item \textbf{func:} референцу на функцију коју извршава,
    \item \textbf{description:} опис намјене алата.
\end{itemize}

Размотримо пример једноставног алата -- функције која враћа тренутни датум. Прво ћемо дефинисати Python функцију, а затим је регистровати као алат са именом и описом:

\begin{lstlisting}[language=Python, caption={Регистрација простог алата за тренутни датум}]
from datetime import datetime
from langchain_core.tools import Tool

# Дефинишемо функцију која враћа тренутни датум у формату ГГГГ-ММ-ДД
def get_current_date() -> str:
    """Враћа тренутни датум као стринг у формату YYYY-MM-DD."""
    return datetime.now().strftime("%Y-%m-%d")

# Креирамо Tool објекат за регистрaцију алата
current_date_tool = Tool(
    name="get_current_date",
    func=get_current_date,
    description="Корисно када агенту треба данашњи датум у формату ГГГГ-ММ-ДД"
)
\end{lstlisting}

Горњи код илуструје креирање прилагођеног алата. Функција get\_current\_date има једноставан документован опис (доцстринг) који објашњава шта ради. Затим конструишемо Tool објекат коме дајемо јединствено име ``get\_current\_date'', прослеђујемо саму Python функцију, и наведемо опис алата. Опис ће LangChain укључити у промпт агента тако да LLM ``зна'' да тај алат даје тренутни датум, те ће га позвати када кориснички задатак то захтева. После овакве регистрације, тај алат додајемо у листу алата које агент може користити (нпр. tools = [current\_date\_tool]). Уколико бисмо имали више алата, све их укључимо у ту листу коју касније предајемо агенту.

Важно је напоменути да се алати у LangChain-у могу правити и другим средствима (нпр. декоратором @tool који аутоматски користи назив функције и њен docstring као име и опис алата \cite{langchain_docs_2024}), али принцип је увек исти: дефинише се функција са јасним описом и затим се региструје тако да је LLM може позвати током рада агента.

\subsubsection{Коришћење меморије}

Да би разговор са агентом био кохерентан и контекстуалан, неопходно је да агент има неку врсту меморије -- механизма за памћење претходних интеракција. Меморија омогућава да агент ``зна'' шта је већ речено у разговору, тако да може да користи тај контекст при генерисању следећих одговора. Без меморије, сваки упит би се третирао изоловано, што би довело до фрагментираних, неповезаних разговора \cite{langchain_docs_2024}. LangChain зато обезбеђује класе за меморију које се могу укључити у ланце или агенте.

Постоји више врста меморије у LangChain-у, а две важне су:
\begin{itemize}
    \item \textbf{ConversationBufferMemory} -- меморија која чува комплетну историју разговора као низ порука (сваког питања корисника и одговора модела). Она представља најједноставнији облик: свака нова интеракција се додаје на крај меморијског буфера. Овај приступ осигурава да модел увек има комплетан контекст свих претходних размена, али може довести до великог броја токена ако је разговор дугачак.
    \item \textbf{ConversationSummaryMemory} -- меморија која чува сажетак разговора уместо пуне историје. Користи LLM да након одређеног броја интеракција или када историја постане предуга, сажме досадашњи разговор у краћи резиме, који се затим користи као контекст уместо оригиналних порука. На тај начин се штеди на дужини контекста (мање потрошених токена), омогућавајући дуже разговоре \cite{langchain_docs_2024}. Предност овог приступа је што агент може водити значајно дужи дијалог без губитка целокупног контекста, по цену ослањања на модел да направи добар сажетак.
\end{itemize}

Меморија је битна јер побољшава конзистентност агента: ако корисник постави пратеће питање, агент може да се позове на раније податке. На пример, ако корисник најпре пита „Какво је време у Токију данас?'', а затим „А шта је са сутрашњим временом?'', агент уз меморију разуме да се друго питање односи на временску прогнозу у Токију без да му се то експлицитно понови \cite{langchain_docs_2024}. Без меморије, агент би сваки пут видео само појединачно питање и не би повезао да се ``сутра'' односи на исти град.

У пракси, додавање меморије агенту у LangChain-у је једноставно -- при инициализацији ланца или агента проследимо објекат меморије као параметар. Приликом сваког позива, LangChain ће аутоматски ажурирати меморију новим корисничким уносом и одговором модела. Укратко, интеграција меморије се изводи овако:

\begin{lstlisting}[language=Python, caption={Креирање агента са меморијом}]
from langchain.memory import ConversationBufferMemory
from langchain.agents import initialize_agent, AgentType

# 1. Креирамо објекат меморије (овде бафер који чува целу историју)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# 2. Иницијализујемо LLM модел и листу алата (нпр. из претходне секције)
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
tools = [current_date_tool]  # листа алата, претходно дефинисана

# 3. Иницијализујемо агента са меморијом
agent_chain = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    memory=memory,
    verbose=True
)

# 4. Сада агенту можемо поставити упит, а меморија ће се аутоматски ажурирати
response = agent_chain.run("Koji je danas datum?")
print(response)
\end{lstlisting}

У горњем примеру, користимо ConversationBufferMemory за чување историјата разговора (параметар memory\_key=``chat\_history'' одређује назив променљиве у шаблону промпта где ће се меморија убацити, а return\_messages=True да меморија враћа листу порука уместо спојеног низа). Затим правимо агента помоћу функције initialize\_agent, прослеђујући листу алата, LLM, тип агента (о чему више у наредном одељку) и објекат меморије. Када позовемо agent\_chain.run(...), агент ће добити приступ меморији и сваки његов одговор биће заснован на комплетном контексту разговора. После позива, memory објекат ће садржати и управо постављено питање и одговор, што омогућава агенту да на следеће питање одговори у контексту целе претходне конверзације.

\subsubsection{Реактивно покретање агента (ReAct AgentExecutor)}

ReAct (скраћено од Reasoning and Acting) је приступ у коме LLM агент комбинује размишљање у више корака са извршавањем радњи над алатима \cite{langchain_docs_2024}. Уместо да једноставно генерише одговор из упита у једном кораку, ReAct агент реагује на самом задатку тако што наизменично спроводи мисли (односно, интерно образложење шта треба да ради) и акције (конкретне позиве алата), све док не дође до коначног одговора. Овај процес се одвија у петљи: модел генерише размишљање о томе шта је корисник затражио, одлучује који алат (ако било који) треба да употреби, затим се та акција извршава и добија се опажање (резултат алата), које се враћа моделу. Након тога, агент наставља да размишља на основу новодобијених информација и одлучује о наредном кораку. Ова алтернација мисли, акција и опажања се понавља све док агент не закључи да има довољно информација да формира финални одговор \cite{langchain_docs_2024}. ReAct стратегија омогућава агенту да се прилагоди током извршавања -- на основу резултата претходних акција, агент може променити свој план и предузети нове кораке ка решењу, слично људском начину решавања сложених задатака.

У LangChain-у, да би агент радио у ReAct режиму, потребно је да буде конфигурисан са списком алата које сме да користи, одговарајућим LLM моделом, и (опционо) меморијом за вођење дијалога. Такође му је потребан prompt који имплементира ReAct логику -- обично специјално дизајниран шаблон који агенту даје инструкције да користи формат Мисао/Акција/Опажање. LangChain већ садржи уграђене prompt шаблоне за ReAct агенте, тако да их није нужно ручно писати. При креирању агента, можемо искористити константу типа агента AgentType.ZERO\_SHOT\_REACT\_DESCRIPTION, што означава управо ReAct агента који сам из описа алата бира који му је потребан (zero-shot приступ без претходних примера) \cite{langchain_docs_2024}. У примерима, већ смо користили функцију initialize\_agent са тим типом да направимо агента. Алтернативно, LangChain нуди и функцију create\_react\_agent за експлицитно прављење ReAct агента, као и класу AgentExecutor којом се финални агент покреће \cite{langchain_docs_2024}. У пракси, initialize\_agent(..., agent=AgentType.ZERO\_SHOT\_REACT\_DESCRIPTION, ...) враћа управо AgentExecutor спреман за коришћење.

Да илуструјемо покретање агента у ReAct режиму, наставићемо се на претходни пример. Већ смо креирали агента са именом agent\_chain који има један алат (get\_current\_date) и меморију. Поставимо му упит који захтева комбиновано резоновање и коришћење алата, на пример: ``Који је данас датум и колико дана има до краја месеца?''. ReAct агент треба прво да схвати да му је потребан данашњи датум (за шта има алат), да га дохвати, а онда да израчуна преостале дане у месецу. Покренимо агента:

\begin{lstlisting}[language=Python, caption={Покретање ReAct агента}]
query = "Који је данас датум и колико дана има до краја месеца?"
response = agent_chain.run(query)
print(response)
\end{lstlisting}

Приликом оваквог позива, агент ће интерно генерисати низ ``мисли'' и ``акција''. Могући ток би изгледао овако (не нужно дословце видљив кориснику, већ у позадини размишљања модела):
\begin{enumerate}
    \item Мисао: ``Питање тражи данашњи датум и број дана до краја месеца. Прво треба да сазнам данашњи датум.''
    \item Акција: Позива алат get\_current\_date.
    \item Опажање: Алат враћа, рецимо, ``2025-09-19''.
    \item Мисао: ``Данас је 19. септембар 2025. Треба израчунати колико дана има до 30. септембра 2025.'' (модел може ово урадити унутрашње, без новог алата).
    \item Акција: (Није неопходна нова спољна акција, модел може сам да рачуна)
    \item Опажање: (Није примењиво, рачун је унутрашњи)
    \item Мисао: ``Остало је 11 дана до краја септембра.''
    \item Коначан одговор: ``Данас је 19. септембар 2025. године, и преостало је 11 дана до краја месеца.''
\end{enumerate}

Наравно, сам корисник добија само коначни одговор, док су кораци размишљања и акције извршене у позадини. Реактивно понашање овде се огледа у томе да агент није унапред знао које ће алате употребити или какву ће стратегију применити, већ је динамички одлучивао у ходу на основу самог питања и резултата међукорака. LangChain-ов ReAct агент уз помоћ AgentExecutor-а управља овим циклусом, што програмеру омогућава да једноставно проследи упит агенту као једну функцију, док се сложена логика одвија аутоматски ``иза сцене''. Резултат је снажан систем који може да обавља комплексне задатке комбинујући више корака резоновања и коришћења алата, дајући прецизне и контекстуалне одговоре \cite{langchain_docs_2024}.



\section{Python EDGAR библиотеке за обраду 10-K извештаја}

Наш LLM агент је специјализован за рад са финансијским извештајима компанија -- конкретно, годишњим извештајима познатим као Form 10-K. Form 10-K је годишњи извештај који америчке јавно-трговане компаније обавезно подносе Комисији за хартије од вредности (SEC). Сви 10-K и остали обавезни извештаји доступни су електронски путем SEC-овог EDGAR система (енг. \textit{Electronic Data Gathering, Analysis, and Retrieval}), који омогућава претраживање и преузимање тих докумената \cite{wikipedia_form_10k_2025}.

За нашу примену, потребно је аутоматски приступати 10-K извештајима и из њих издвајати одређене информације (нпр. одељак ``Risk Factors'' или финансијске бројке) које ће LLM анализирати. Ручно прикупљање и читање тако обимних докумената било би непрактично, стога се ослањамо на Python библиотеке за EDGAR које омогућавају да се овај процес аутоматизује.

Неколико истакнутих Python алата за рад са EDGAR подацима су:
\begin{itemize}
    \item \textbf{edgar} библиотека: Једноставна Python библиотека која пружа интерфејс за приступ EDGAR архиви; омогућава претрагу по називу или CIK, преузимање најновијег 10-K и екстракцију текста \cite{pypi_edgar_2024}.
    \item \textbf{EDGAR API клијенти:} Модерни клијенти за званични SEC API омогућавају претрагу поднесака и директно преузимање у JSON/XML облику.
    \item \textbf{Парсери SEC докумената:} \textit{sec-parser} разлаже HTML 10-K на семантичке секције (наслови, пасуси, табеле), што поуздано омогућава извлачење релевантних делова попут ``Item 1A. Risk Factors'' \cite{sec_parser_docs_2023}.
    \item \textbf{SEC Extractor API (sec-api):} Комерцијални API и Python пакет за једноставно извлачење конкретних одељака (нпр. ``Item 7'') и конверзију табела у структуре погодне за анализу \cite{sec_api_tutorial_2023}.
\end{itemize}

У примени нашег агента, планирамо да користимо комбинацију наведених техника: аутоматизовано преузимање 10-K извештаја (edgar/SEC API), почетно парсирање (\textit{sec-parser}/sec-api) и усмерено прослеђивање релевантних сегмената LLM-у. Овај корак претходне обраде смањује количину текста коју LLM анализира (трошак/прозор контекста) и повећава тачност података које модел разматра. Уз LangChain-ове документ лоудере и векторске базе, 10-K делови могу се индексирати ембединзима и претраживати семантички у RAG парадигми \cite{ibm_what_is_langchain_2023,patriwala_langchain_2025}.

На основу доступне литературе и алата, можемо илустровати могућности овакве обраде на конкретном примеру: узимање последњег 10-K извештаја компаније IBM и екстракција два различита дела. Прво, користећи \textit{edgar} библиотеку, преузимамо HTML садржај извештаја и потом га прослеђујемо \textit{sec-parser} алату који га дели на семантичке секције. Потом:
\begin{itemize}
    \item Ако желимо квалитативне информације, попут описа пословања и ризика, можемо из парсираног стабла издвојити чланке означене као ``Item 1. Business'' или ``Item 1A. Risk Factors'' и добити чист текст тих секција. Ове секције често садрже више пасуса текста и могу бити обрађене LLM-ом ради сумирања или Q\&A (нпр. „Како компанија описује утицај конкуренције на своје пословање у последњем 10-K?").
    \item Ако су нам потребне квантитативне информације, попут финансијских показатеља, можемо фокусирано извући табеларне делове 10-K. Коришћењем \textit{sec-api} или мануелно уз \textit{BeautifulSoup}, могуће је наћи табеле (нпр. биланс успеха, биланс стања) и конвертовати их у структуру погодну за анализу (рецимо DataFrame у Pandas-у). Тај бројчани контекст можемо проследити LLM моделу уз упутство да га протумачи (нпр. „На основу приложене табеле прихода и расхода из последње три године, објасни тренд прихода компаније.").
\end{itemize}

Закључно, Python EDGAR алати значајно проширују могућности LLM агента, омогућавајући му да буде специјализован за рад са извештајима. Комбинујући те податке са моћним разумевањем језика модела GPT-4, систем може да даје квалитетне одговоре -- како описне (сумирање наративних делова), тако и аналитичке (поређење метрика) -- на питања у вези са пословањем компанија. Овај интегрисани приступ спаја снагу LLM-а са прецизношћу доменских алата, што је кључно за научно-истраживачки рад који укључује обраду великих текстуалних финансијских података.



\subsection{Приступ резоновању агента: планско-извршни наспрам реактивног}

Приликом осмишљавања логике резоновања агента, размотрена су два приступа како LLM доноси одлуке о коришћењу алата током решавања задатка: (1) планско-извршни приступ и (2) реактивни приступ.

У планско-извршном приступу ("plan and execute"), агент најпре покушава да изради целовит план корака пре него што започне извршење. То значи да LLM у оквиру једног размишљања генерише секвенцу акција (нпр. којим редом и које алате треба позвати) како би дошао до решења, а потом се ти кораци спроводе један по један. Предност оваквог начина је што може бити користан код веома сложених задатака који захтевају дугорочно планирање -- модел унапред сагледава комплетан проблем и осмишљава стратегију. Међутим, ово долази по цену већег когнитивног оптерећења модела и потенцијалних грешака у планирању. Ако LLM не успе тачно да предвиди све што је потребно, унапред сачињен план може бити непотпун или погрешан, што доводи до тога да агент креће у погрешном смеру. У контексту нашег финансијског домена, где су питања углавном директно усмерена на конкретне податке или прорачуне, овако детаљно планирање у већини случајева није неопходно.

Супротно томе, реактивни приступ подразумева да агент размишља и дела у наизменичним корацима, доносећи одлуке о наредној акцији у ходу, на основу тренутно доступних информација. Овај стил резоновања често се назива ReAct (спајање reasoning и acting). У пракси, то значи да LLM анализира кориснички упит (или међурезултат ако је неки корак већ обављен), одлучује који алат у том тренутку треба применити, извршава тај алат, па затим сагледава добијени резултат и одлучује о следећем кораку. Агент се, дакле, прилагођава у реалном времену без унапред фиксног плана. Предност реактивног приступа је његова једноставност и флексибилност: модел може да реагује на непредвиђене околности или новодобијене информације тако што ће променити ток акција у ходу. Такође, избегава се двоструко ангажовање модела (посебно одвојена фаза планирања па извршавања), што смањује укупан когнитивни терет и време извршења за типичне задатке.

У дизајну нашег агента одлучили смо се за реактивни приступ резоновању. Ова одлука донета је након што смо сагледали природу задатака у датасету и сложеност упита. Већина захтева које агент треба да обради релативно су фокусирани (нпр. тражи се одређени финансијски показатељ или израчун на основу једног извештаја), те агенту обично није потребан дугачак низ корака да би дошао до одговора. Реактивни начин рада показао се довољним и ефикасним за овакве ситуације -- LLM може у једном кораку закључити који му је алат потребан (нпр. "извуци биланс стања", затим "обрачунај ROE") и добити одмах резултат, без формалног планирања целокупне стратегије. Поред једноставности, реактивни приступ је олакшао и развој и тестирање система, јер је лакше пратити и разумети ток одлучивања агента када он корак-по-корак образлаже и спроводи акције.

Насупрот томе, планско-извршни приступ би додао сложеност без јасне добити за наш домен -- морали бисмо да имплементирамо додатну фазу планирања и да верујемо да ће LLM увек правилно исцртати план, што у нашим експериментима није донело боље резултате. Стога смо закључили да је реактивни приступ примеренији: агент је у стању да брже и поузданије дође до решења финансијских упита ослањајући се на постепено резоновање и прилагођавање, што се показало успешним у евалуацији.